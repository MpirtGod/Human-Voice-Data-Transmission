{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5bd6ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "file = pd.read_excel('russian_speech.xlsx')\n",
    "y = [sentence for sentence in file['Русская речь']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c07a1495",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torchaudio\n",
    "\n",
    "dir_name = \"abnormal_voice/\"\n",
    "files_in_dir = [f for f in os.listdir(dir_name)]\n",
    "\n",
    "samp = 0\n",
    "X = []\n",
    "for i in files_in_dir:\n",
    "    speech_array, sampling_rate = torchaudio.load(dir_name + i)\n",
    "    X.append(speech_array)\n",
    "    samp = sampling_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "932f7224",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    train_size=0.7, \n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00feb060",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "chars_to_ignore_regex = '[\\,\\?\\.\\!\\-\\;\\:\\\"\\“\\%\\‘\\”\\�\\\\xad\\\\n\\–]'\n",
    "\n",
    "def remove_special_characters(sentence):\n",
    "    sentence = re.sub(chars_to_ignore_regex, '', sentence).lower() + \" \"\n",
    "    sentence = sentence.replace('4', 'четыре')\n",
    "    sentence = sentence.replace('р220', 'эр двести двадцать')\n",
    "    sentence = sentence.replace('6', 'шесть')\n",
    "    return sentence\n",
    "\n",
    "y = list(map(remove_special_characters, y))\n",
    "y_train = list(map(remove_special_characters, y_train))\n",
    "y_test = list(map(remove_special_characters, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe6b8dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "fullY = ''.join(y)\n",
    "fullY = fullY.split()\n",
    "fullY = ' '.join(fullY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c2ed3d47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'к': 677, 'а': 1501, 'п': 503, 'р': 825, 'о': 1716, 'й': 287, 'т': 1140, 'и': 1079, 'д': 523, 'у': 458, 'с': 906, 'г': 280, 'е': 1445, 'в': 661, 'з': 313, 'я': 391, 'ь': 399, 'н': 1102, 'л': 744, 'б': 320, 'м': 519, 'э': 43, 'ю': 99, 'ц': 111, 'х': 103, 'ч': 247, 'ё': 59, 'ы': 334, 'ш': 151, 'ф': 44, 'ж': 158, 'щ': 50, '́': 107, 'ъ': 4, '|': 3056}\n"
     ]
    }
   ],
   "source": [
    "vocab_dict = {}\n",
    "for x in fullY:\n",
    "    for t in x:\n",
    "        if t in vocab_dict:\n",
    "            vocab_dict[t] += 1\n",
    "        else:\n",
    "            vocab_dict[t] = 1\n",
    "\n",
    "vocab_dict['|'] = vocab_dict[' ']\n",
    "del vocab_dict[' ']\n",
    "print(vocab_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "53eae5c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_dict[\"[UNK]\"] = len(vocab_dict)\n",
    "vocab_dict[\"[PAD]\"] = len(vocab_dict)\n",
    "len(vocab_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "41b59222",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('vocab.json', 'w') as vocab_file:\n",
    "    json.dump(vocab_dict, vocab_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0bdb69e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import Wav2Vec2CTCTokenizer\n",
    "\n",
    "tokenizer = Wav2Vec2CTCTokenizer.from_pretrained(\"./\", unk_token=\"[UNK]\", pad_token=\"[PAD]\", word_delimiter_token=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "19e4d497",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampl_conver(speech_array):\n",
    "    resampler = torchaudio.transforms.Resample(sampling_rate, 16_000)\n",
    "    sentc = resampler(speech_array).squeeze().numpy()\n",
    "    return sentc\n",
    "\n",
    "X_train = list(map(sampl_conver, X_train))\n",
    "X_test = list(map(sampl_conver, X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "49976b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Wav2Vec2FeatureExtractor\n",
    "\n",
    "feature_extractor = Wav2Vec2FeatureExtractor(feature_size=1, sampling_rate=16000, padding_value=0.0, do_normalize=True, return_attention_mask=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2332bc8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Wav2Vec2Processor\n",
    "\n",
    "processor = Wav2Vec2Processor(feature_extractor=feature_extractor, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e35a7a27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\source\\tenserflow\\venv\\lib\\site-packages\\transformers\\models\\wav2vec2\\processing_wav2vec2.py:155: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "def prepare_dataset(audioX, textY):\n",
    "    data_list = []\n",
    "    for i in range(len(audioX)):\n",
    "        d = {}\n",
    "        d['input_values'] = processor(audioX[i], sampling_rate=16000).input_values[0]\n",
    "        d['input_length'] = len(d[\"input_values\"])\n",
    "        with processor.as_target_processor():\n",
    "            d[\"labels\"] = processor(textY[i]).input_ids\n",
    "        data_list.append(d)\n",
    "    return data_list\n",
    "\n",
    "train_list = prepare_dataset(X_train, y_train)\n",
    "test_list = prepare_dataset(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
